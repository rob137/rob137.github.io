# Blog Post Backlog

Ideas extracted from ambient recordings and conversations.

---

## Published

### Voice-First: The Future of Talking to Machines
**Published:** 2026-01-02
**Core idea:** Speech as input is the future. Just-in-time learning through conversation. "I can do audio engineering now - it's like the Matrix."

### How This Blog Exists
**Published:** 2026-01-02
**Core idea:** The friction collapse. Set up a blog via phone prompts while parenting. Ambient content pipeline.

### The GUI Was a Detour
**Published:** 2026-01-02
**Core idea:** Software makes you think about two things: your problem AND its mental model. LLMs let you think only about your problem. The barrier is scoping, not coding.

### Respecting the Fence
**Published:** 2026-01-02
**Core idea:** Chesterton's fence - LLMs let you respect bureaucratic processes without being crushed by them. The vicar/church story. Intelligence corps background.

### Books as Compressed Prompts
**Published:** 2026-01-02
**Core idea:** Book titles are pointers to compressed mental models LLMs already know. Reading leverage is higher than ever - people reading less, payoff greater.

### Crossing the Horizon
**Published:** 2026-01-02
**Core idea:** A step change in model capability that went unrecognized for weeks. The practitioner's view - "I don't understand transformers but I know when the instrument changes." Teacher marking homework, colleague using terminal, broader implications. Event horizon metaphor - crossing feels normal locally, but there's no way back.

### The Music Stopped
**Published:** 2026-01-02
**Core idea:** IDE vs terminal debate is becoming irrelevant - not because one won, but because the underlying activity changed. Edit (maybe), chat, review. The desire lines are clear. Includes Yegge quote, Ousterhout naming styles, personality attractors.

### The Intermediary Times
**Published:** 2026-01-02
**Core idea:** Industrial Revolution parallel - net positive but expensive in the intermediary times. Social contract concerns. Not accelerationist or doomer - eye of the beholder.

### How I Keep Up
**Published:** 2026-01-02
**Core idea:** X.com is unreasonably good if you follow the right people. 80/20 sources: Simon Willison's blog and Latent Space. Health warning about dopaminergic loops and context switching costs.

### The Golden Retriever Problem
**Published:** 2026-01-02
**Core idea:** The helpful assistant persona is a "radio on TV" transitional form. The ideal employee isn't a helpful assistant - true for humans, and once models reach competence, wrong for them too. Staff engineer comparison. This is fixable.

### To-Do Lists as Prompts
**Published:** 2026-01-02
**Core idea:** Writing detailed to-do items is actually writing prompts. Speech-to-text makes this easier than typing laconic notes. Rather than keeping prompts, you might just send them. Fire and forget with worktrees. Bake in success criteria and validation.

### The Last Bastion
**Published:** 2026-01-02
**Core idea:** Samaritans as pure human-touch work. LLMs can already do active listening well. The service filters for people comfortable calling strangers - what about those who aren't? Not proposing anything, just observing what seems inevitable. If even this isn't safe, what is?

### Show, Don't Tell
**Published:** 2026-01-02
**Core idea:** Prosumer decision-making. Spent 2 hours finding a product via LLM iteration - then realized showing past purchases (without explanation) got the right answer immediately. LLMs drawing parallels, associative thinking, category hopping. Links to golden retriever problem. Open-ended musings.

### YOLO Mode
**Published:** 2026-01-02
**Core idea:** Every abstraction leap has a liminal period where the new thing is dismissed. What's "YOLO" becomes normal - web devs never read assembly output anymore. Current debates about line-level vs commit-level vs PR-level review may all become quaint. Yegge's "Gas Town" as evidence of where things are heading.

---

### The Witnesses
**Published:** 2026-01-03
**Core idea:** Opens with John Blow's skepticism as the bar to meet. Then presents quotes from respected programmers expressing genuine surprise - Jaana Dogan, ESR, Yegge, Gene Kim, Karpathy, Hassabis, Brin. List will grow.

**Still collecting:** Mitchell Hashimoto quote/screenshot.

### Too Comfortable
**Published:** 2026-01-03
**Core idea:** Terminal agents stable for a year (Aider â†’ Claude Code). Jeff Tang satire captures the churn. Huang's law, Leopold Aschenbrenner/Sutskever on scaling. If 4x every 18 months continues, current comfort should feel suspicious.

### First Contact
**Published:** 2026-01-03
**Core idea:** Three military concepts for AI agents: mission command (what not how), orders process (plan thoroughly, hold loosely), inkblot strategy (agency spreads organically). Intelligence Corps background, Sandhurst, Para Reg.

### The Pliers
**Published:** 2026-01-03
**Core idea:** Software engineers' blue-collar fantasies. Attachment to physical tools (pliers) paralleling attachment to coding paradigms that are becoming obsolete. What to do with attachment when tools change this fast?

---

### Is It Cheating?
**Published:** 2026-01-03
**Core idea:** Warfare analogy - technology arrives, gets called dishonorable, rules shift. Meta description of the dictation workflow. Copywriter parallel (CEO articles aren't written by CEOs). The filter of writing vs speech. Orders of magnitude more output.

### Position Before Submission
**Published:** 2026-01-03
**Core idea:** BJJ parallel. Early exhaustion vs efficient black belts. "Spending surprise" as the new debt - stay in the training distribution. Principle of least surprise (162 mentions in chat history). Position before submission = make architecture obvious so models just know.

### The Interview Question
**Published:** 2026-01-03
**Core idea:** Calculator app task that's now one-shottable. "Yeah, whatever you like" soundboard. Looking for product ownership over technical depth. "Calculator" used to be a job title - software engineer heading somewhere similar.

### Brooks' Law Redux
**Published:** 2026-01-03
**Core idea:** Human friction becoming the bottleneck. "The Goal" theory - as AI speeds everything up, interpersonal coordination sticks out. "The worst thing anyone could say is that someone else is going to work on it with me." Optimal engineers approaching zero. Jevons Paradox on project count. Metal Gear Solid exclamation mark ending.

---

## Backlog

### How Hiring Has Changed
**Status:** Idea - reading Joel Spolsky's book
**Core idea:** Reflections on how hiring has changed in the AI era. Reading Joel Spolsky's hiring book (based on his blog). More to come.

### The Raft and the Ladder
**Status:** Idea
**Core idea:** Buddhist raft metaphor (use it to cross the river, don't carry it with you). Wittgenstein's ladder (climb it, then throw it away). Relationship with rapidly obsoleting skills and the abstraction/orchestration ladder. Key question: does climbing the ladder take you somewhere better, or does it leave you worse off in some ways - less comfortable with how things actually work, further from the ground? Is expertise a ladder (you climb but can still see below) or a raft (you cross and leave the other shore behind)?

### The Role of Testimony
**Status:** Idea
**Core idea:** Most knowledge is testimonial - I don't know how penicillin works, why brushing twice beats once but six is overkill, how a light switch actually works. We trust experts constantly. Trust is a big topic around AI, especially when you can find failure examples. But humans fail too. Autonomous driving is machines catching up to and exceeding human error rates - we'll watch the same in coding. Because machines don't follow human quirks, our trust heuristics will be miscalibrated. We might struggle to trust them well after the point where we should have.

### The Expanding Universe
**Status:** Idea - collecting quotes
**Core idea:** Models are good for X but not for Y. Systems programming, low-level optimization, novel physics - AI harnesses hinder more than help. But in web dev, people ship without reading code. There's a spectrum of how much you can get away with. Working practices are diverging across domains - like the universe expanding, distances growing. Practices that feel sensible in one domain may be extremely domain-specific. People anchor to what worked yesterday.

**Quotes collected:**
- [ ] Jonathan Blow - [need tweets]
- [x] ThePrimeagen (Lex Fridman #461): AI "often gets it wrong, especially with larger, more complex codes... lacks deep understanding for problem-solving and design"
- [x] George Hotz (Lex Fridman #387): "GPT is great for quick generic scripts, but not for complex tasks"
- [x] Andrej Karpathy - CONTRAST:
  - Dwarkesh (Oct 2025): nanochat was "intellectually intense code... everything has to be very precisely arranged" - AI "net unhelpful", called code "slop"
  - X post (Dec 26, 2025): "I've never felt this much behind as a programmer. The profession is being dramatically refactored." Said AI can make devs "10X more powerful"
- [x] DHH - CONTRAST:
  - Lex Fridman (summer 2025): "not letting AI write any code directly"
  - X post (Jan 3, 2026): "half the resistance was simply that the models weren't good enough yet... That has now flipped." Working with opencode "has been a blast. Watching the thinking models nail a difficult bug is a revelation."
- [?] Robert C. Martin (Uncle Bob) - CONSISTENT SKEPTIC (may not fit the narrative):
  - May 2025: "efficiency boost... nowhere near 8X. I would put it at about 10%. That's because all of the code presented by the AI requires scrutiny, and a large fraction is crap."
  - Dec 2025: "AI was a help. I got farther than I would have without it. But not that much farther." Still using hybrid approach, AI for "boring repetitive work"
  - Hasn't flipped like Karpathy/DHH - remains measured. Could show the spectrum includes holdouts?

---

*Last updated: 2026-01-03*
