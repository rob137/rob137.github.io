---
layout: post
title: "The Intermediary Times"
date: 2026-01-02 14:00:00 +0000
tags: [ai, society, disruption, observations]
---

I've never really worried about my job.

That's not complacency - I'm aware of what's happening. I've been using LLMs for coding since before ChatGPT launched. I've watched the capabilities accelerate. I know the trajectory. But I've always felt more excited than threatened. The unlocks are real. The productivity gains are real. Being able to do things that weren't possible before feels like a gift, not a warning.

The minor background trepidation that probably every knowledge worker feels - "will this eventually come for me?" - never bloomed into real concern. I adjusted. I learned to work with the tools. The tools got better. I got more productive. It felt like surfing, not drowning.

But lately something has shifted. I've stopped worrying about my job and started worrying about the social contract.

## The Industrial Revolution Was Good

I want to be clear about something: I believe the Industrial Revolution was profoundly good for humanity.

Child mortality collapsed. Literacy became near-universal. We got antibiotics, vaccines, MRI machines. Foreign holidays. Infinite entertainment. Space exploration. Central heating. Anaesthesia. The internet. Ben & Jerry's.

The average person today lives better than royalty did three centuries ago. This isn't nostalgia-blind tech optimism - it's just true. The gains are real and they're enormous.

I believe the AI transition will be similar. Net positive. Enormously so. Things that are currently impossible will become trivial. Problems that have persisted for generations will dissolve. The unlocks will be real.

## But It Wasn't Free

Here's what I've been thinking about: the Industrial Revolution also gave us the world wars.

Not directly, not simply, but not coincidentally either. The same forces that created unprecedented prosperity also created unprecedented disruption. Old social contracts broke down. Entire ways of life disappeared within a generation. People who had known their place in the world suddenly didn't. The transition was, in aggregate, enormously positive - but the intermediary times were expensive.

The cold war. The war on terror. Mass displacement. The opioid crisis. These aren't unrelated to the forces that also gave us vaccines and space travel. Disruption creates winners and losers. The losers don't disappear quietly. The social fabric frays before it reweaves.

I've started to think that disruption can cause death as a rule, even when it's impossible to deny the greater good it brings.

## The Social Contract Question

A lot of assumptions about what constitutes good, honest, valuable work are about to be stress-tested.

I wrote [a post earlier today](/2026/01/02/respecting-the-fence/) about helping a church complete government paperwork using an LLM. An hour of my time, zero domain expertise, almost no corrections needed. That capability simply didn't exist a few months ago.

I know a teacher who marks English literature homework with LLMs. A month ago it needed constant correction. Now it's no-notes, no-intervention. She's still reviewing, but she's never overriding.

I have a colleague who's never written a line of code, now using the terminal as his primary interface with the computer. Speech-to-texting his intent, letting agents execute.

These are small examples. But scale them across white-collar work and you start to see the shape of something. A lot of people have built their identities, their sense of worth, their economic security on skills that are rapidly being commoditised.

What happens to them? Not in the long run - in the long run, I suspect new roles emerge, new forms of value get created, the economy adjusts. But in the intermediary times?

## Toothpaste Out of the Tube

I don't know if this makes me an accelerationist or a doomer. Maybe it's an eye-of-the-beholder thing.

I'm not saying we should stop. I don't think we *can* stop - the prisoner's dilemma between labs, between nations, makes that almost structurally impossible. The toothpaste is out of the tube. The train has left the station. Pick your metaphor.

And I'm not saying the destination is bad. I genuinely believe it's good. The unlocks are real. The suffering that gets alleviated is real. The capabilities that emerge are real.

But I've stopped being able to ignore the cost of the transition. The intermediary times are expensive. They always have been. People don't just calmly accept that their skills are obsolete and retrain. Social contracts don't update smoothly. The fraying comes before the reweaving.

## 2026

I think this is the year people start to notice.

Not the AI enthusiasts - we've been living in this for a while. But everyone else. The teacher who suddenly doesn't need to mark homework. The analyst whose reports write themselves. The administrator whose paperwork completes itself.

The capabilities have crossed some threshold. The reliability has crossed some threshold. The accessibility - through tools like [Claude Code](https://docs.anthropic.com/en/docs/claude-code) and its equivalents - has crossed some threshold.

I don't know what happens next. I suspect it's net positive, eventually. I suspect it's expensive, in the meantime.

The intermediary times are where we live now.
