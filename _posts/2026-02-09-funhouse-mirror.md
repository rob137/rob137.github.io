---
layout: post
title: "Funhouse mirror"
date: 2026-02-09 13:38:00 +0000
tags: [ai, software]
excerpt: "AI coding expertise is fragile. Late arrivals might actually have an advantage."
image: /assets/images/funhouse-mirror.webp
---

![Funhouse mirror](/assets/images/funhouse-mirror.webp)

I've been using AI agents for coding all day, every day, for over a year now. And it occurred to me that the expertise I've built is pretty fragile.

The Lindy effect says that anything that hasn't been around for long probably won't be around much longer. Case in point: I've watched my AI workflows get replaced quicker and quicker. The tricks I learned six months ago are often obsolete.

Part of this is Rich Sutton's [bitter lesson](http://www.incompleteideas.net/IncsIdeas/BitterLesson.html) playing out. But part of it is just that intelligence is multidimensional, and models are getting better at inferring intent, drawing out requirements, presenting things in ways that make adjustments intuitive. Exactly the things that tool familiarity helps you overcome.

Which means arriving late to the party, you have far less to learn.

For years, the terminal was the sole point of entry to a computer. It's an opaque, difficult environment - not obvious what's possible. GUIs changed that by presenting possibilities intuitively, without language. The terminal hides things. It's a natural home for power users, but there's a lot of pain to eat if you want to become one.

We're moving from a terminal era to something more natural. I still work in a terminal emulator all day, but I haven't typed actual commands in months. Natural language, speech to text, coding agents. The terminal is incidental now.

The models have common sense. User barriers that were real 18 months ago aren't there anymore.

So there's a bit of an illusion that people who've been using AI tools for a year must be miles ahead. I think the reverse is true. If you've been here a while, you've built up priors with earlier states of the models. If you come in blind and reckless, you'll figure out things that seem silly to incumbents - because of model overhang they don't realise is there.

The slope looks steep, but it isn't. You can onboard yourself pretty quickly just by talking to them. That wasn't true six months ago.

What is happening is that the tools are multiplicative, which stretches out differences between users. Not skill differences - differences in the users themselves. Their intuitions, their ability to articulate and manage, their relationship with the subject matter.

I think of it like a funhouse mirror. It exaggerates differences. People come out looking completely different. And crucially, a funhouse mirror has a very easy UI - you just stand in front of it.

That's where coding agents are heading. Skill will matter less than the differences in the user.

[Peter Steinberger](https://steipete.com/) is an interesting example. He sold a company a while back, took some time off, and basically missed large language models in the coding lifecycle until last summer. Then he built [Moltbot](https://github.com/steipete/macos-automator-mcp) (now renamed a few times), a tool that went massively viral - handing the keys to your digital life to Claude through a harness he built.

He arrived late, with no priors, and spotted something the rest of us were too close to see.

Naivety is becoming a weapon.
