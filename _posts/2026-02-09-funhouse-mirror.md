---
layout: post
title: "Funhouse mirror"
date: 2026-02-09 13:38:00 +0000
tags: [ai, software]
excerpt: "AI coding expertise is fragile. Late arrivals might have less to learn."
image: /assets/images/funhouse-mirror.webp
---

![Funhouse mirror](/assets/images/funhouse-mirror.webp)

I use AI agents for coding all day. And it occurred to me that the expertise I've built is pretty fragile because of the [Lindy effect](https://en.wikipedia.org/wiki/Lindy_effect). Anything that hasn't been around very long probably won't be around much longer. Case in point: my AI workflows keep getting replaced. The tricks I learned six months ago are often obsolete now.

Part of this is [the bitter lesson](http://www.incompleteideas.net/IncsIdeas/BitterLesson.html). But I reckon what's also going on is that intelligence is multidimensional, and models are getting better at inferring intent, drawing out requirements, presenting things in ways that make adjustments intuitive. Exactly the kinds of things that familiarity with tools helps you overcome. Which means arriving late to the party, you have far less to learn.

For years, the terminal was the sole point of entry to a computer. It's opaque. Not obvious what's possible. GUIs present possibilities intuitively, without language. The terminal hides things. It's a natural home for power users, but there's a fair amount of pain to eat if you want to become one.

I think we're moving from a terminal era to something more natural. I still work in a terminal emulator all day, but I haven't written actual commands in months. Natural language, speech to text, coding agents. The terminal is incidental. The models have common sense now, which means barriers that were real 18 months ago aren't there anymore.

There's a bit of an illusion that people who've been using AI tools for a year must be miles ahead. I think the reverse is true. If you've been here a while, you've built up priors with earlier states of the models. If you come in blind and reckless, you'll figure out stuff that seems silly to incumbents because of model overhang they don't realise is there.

The slope looks steep, but it isn't really. You can onboard yourself pretty quickly just by talking to them. That wasn't true six months ago.

What I do think is happening is that the tools are increasingly multiplicative. They're stretching out differences between users. Not skill differences - differences in the users themselves. Their relationship with the subject matter, their ability to articulate and manage.

I think of it like a funhouse mirror. It exaggerates differences. People come out looking completely different. And a funhouse mirror has a very easy UI - you just stand in front of it. That's where coding agents are heading. Skill with AI will matter less than the differences in the user.

[Peter Steinberger](https://steipete.com/) is interesting here. He sold a company a while back, took some time off, and basically missed LLMs in the coding lifecycle until last summer. Then he built [OpenClaw](https://github.com/openclaw/openclaw) (n√©e Moltbot), which went viral - it hands the keys to your digital life to Claude through a harness he built. There are obvious security considerations, but people have historically stomached pretty terrible security compromises when their quality of life improves.

He arrived late, no priors, and spotted something the rest of us were too close to see. Naivety becomes a bit of a competitive advantage.
